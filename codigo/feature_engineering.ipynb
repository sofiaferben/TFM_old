{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b725f012-b11c-4db9-8c7f-bda55da9cf55",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baabe685-3407-4491-97af-dafecca6b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\K6502\\OneDrive\\Desktop\\TFM\\datos\\clean\\dataset_encoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584614bc-efc6-400c-9e27-26ea2bb240c0",
   "metadata": {},
   "source": [
    "**Univariate filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeea3db-8680-4616-a9fd-2002b82ae1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "target_columns = ['synergy_zip', 'synergy_loewe', 'synergy_hsa', 'synergy_bliss']\n",
    "\n",
    "# Feature set (exclude target columns)\n",
    "X = df.drop(columns=target_columns)\n",
    "\n",
    "# Dictionary to store the results\n",
    "univariate_filter_results = {}\n",
    "\n",
    "# Loop through each target and apply SelectKBest\n",
    "for target in target_columns:\n",
    "    y = df[target]\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    scores_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Score': selector.scores_\n",
    "    }).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    univariate_filter_results[target] = scores_df\n",
    "\n",
    "# Example: print top 5 features for each target\n",
    "for target in target_columns:\n",
    "    print(f\"\\nTop features for {target}:\")\n",
    "    print(univariate_filter_results[target].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb601e2-184a-490e-af17-1da12b74ba4e",
   "metadata": {},
   "source": [
    "**Multivariate filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2b001-0a0e-4b3c-9fd6-70613533c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns (everything except targets)\n",
    "feature_columns = [col for col in df.columns if col not in target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d5049-b847-4856-b513-bbeef30b49c0",
   "metadata": {},
   "source": [
    "Option 2: Using Sequential Feature Selector (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099a5fce-141b-4518-a3b5-642bb2567a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m model = RandomForestRegressor(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     25\u001b[39m sfs = SequentialFeatureSelector(model, n_features_to_select=\u001b[32m20\u001b[39m, direction=\u001b[33m'\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m sfs.fit(X_selected, y)\n\u001b[32m     28\u001b[39m selected_features = X_selected.columns[sfs.get_support()].tolist()\n\u001b[32m     29\u001b[39m results[target] = selected_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:282\u001b[39m, in \u001b[36mSequentialFeatureSelector.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    280\u001b[39m     process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, **params)\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     new_feature_idx, new_score = \u001b[38;5;28mself\u001b[39m._get_best_new_feature_score(\n\u001b[32m    283\u001b[39m         cloned_estimator, X, y, cv, current_mask, **params\n\u001b[32m    284\u001b[39m     )\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score - old_score) < \u001b[38;5;28mself\u001b[39m.tol):\n\u001b[32m    286\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:313\u001b[39m, in \u001b[36mSequentialFeatureSelector._get_best_new_feature_score\u001b[39m\u001b[34m(self, estimator, X, y, cv, current_mask, **params)\u001b[39m\n\u001b[32m    311\u001b[39m         candidate_mask = ~candidate_mask\n\u001b[32m    312\u001b[39m     X_new = X[:, candidate_mask]\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     scores[feature_idx] = cross_val_score(\n\u001b[32m    314\u001b[39m         estimator,\n\u001b[32m    315\u001b[39m         X_new,\n\u001b[32m    316\u001b[39m         y,\n\u001b[32m    317\u001b[39m         cv=cv,\n\u001b[32m    318\u001b[39m         scoring=\u001b[38;5;28mself\u001b[39m.scoring,\n\u001b[32m    319\u001b[39m         n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs,\n\u001b[32m    320\u001b[39m         params=params,\n\u001b[32m    321\u001b[39m     ).mean()\n\u001b[32m    322\u001b[39m new_feature_idx = \u001b[38;5;28mmax\u001b[39m(scores, key=\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = cross_validate(\n\u001b[32m    685\u001b[39m     estimator=estimator,\n\u001b[32m    686\u001b[39m     X=X,\n\u001b[32m    687\u001b[39m     y=y,\n\u001b[32m    688\u001b[39m     groups=groups,\n\u001b[32m    689\u001b[39m     scoring={\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: scorer},\n\u001b[32m    690\u001b[39m     cv=cv,\n\u001b[32m    691\u001b[39m     n_jobs=n_jobs,\n\u001b[32m    692\u001b[39m     verbose=verbose,\n\u001b[32m    693\u001b[39m     params=params,\n\u001b[32m    694\u001b[39m     pre_dispatch=pre_dispatch,\n\u001b[32m    695\u001b[39m     error_score=error_score,\n\u001b[32m    696\u001b[39m )\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = parallel(\n\u001b[32m    412\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    413\u001b[39m         clone(estimator),\n\u001b[32m    414\u001b[39m         X,\n\u001b[32m    415\u001b[39m         y,\n\u001b[32m    416\u001b[39m         scorer=scorers,\n\u001b[32m    417\u001b[39m         train=train,\n\u001b[32m    418\u001b[39m         test=test,\n\u001b[32m    419\u001b[39m         verbose=verbose,\n\u001b[32m    420\u001b[39m         parameters=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    421\u001b[39m         fit_params=routed_params.estimator.fit,\n\u001b[32m    422\u001b[39m         score_params=routed_params.scorer.score,\n\u001b[32m    423\u001b[39m         return_train_score=return_train_score,\n\u001b[32m    424\u001b[39m         return_times=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    425\u001b[39m         return_estimator=return_estimator,\n\u001b[32m    426\u001b[39m         error_score=error_score,\n\u001b[32m    427\u001b[39m     )\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    429\u001b[39m )\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = func(*args, **kwargs)\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         estimator.fit(X_train, y_train, **fit_params)\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = Parallel(\n\u001b[32m    488\u001b[39m     n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs,\n\u001b[32m    489\u001b[39m     verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    490\u001b[39m     prefer=\u001b[33m\"\u001b[39m\u001b[33mthreads\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    491\u001b[39m )(\n\u001b[32m    492\u001b[39m     delayed(_parallel_build_trees)(\n\u001b[32m    493\u001b[39m         t,\n\u001b[32m    494\u001b[39m         \u001b[38;5;28mself\u001b[39m.bootstrap,\n\u001b[32m    495\u001b[39m         X,\n\u001b[32m    496\u001b[39m         y,\n\u001b[32m    497\u001b[39m         sample_weight,\n\u001b[32m    498\u001b[39m         i,\n\u001b[32m    499\u001b[39m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[32m    500\u001b[39m         verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    501\u001b[39m         class_weight=\u001b[38;5;28mself\u001b[39m.class_weight,\n\u001b[32m    502\u001b[39m         n_samples_bootstrap=n_samples_bootstrap,\n\u001b[32m    503\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    504\u001b[39m     )\n\u001b[32m    505\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[32m    506\u001b[39m )\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = func(*args, **kwargs)\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    187\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     tree._fit(\n\u001b[32m    190\u001b[39m         X,\n\u001b[32m    191\u001b[39m         y,\n\u001b[32m    192\u001b[39m         sample_weight=curr_sample_weight,\n\u001b[32m    193\u001b[39m         check_input=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    194\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    195\u001b[39m     )\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     tree._fit(\n\u001b[32m    198\u001b[39m         X,\n\u001b[32m    199\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    203\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m builder.build(\u001b[38;5;28mself\u001b[39m.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "target_columns = ['synergy_zip', 'synergy_loewe', 'synergy_hsa', 'synergy_bliss']\n",
    "feature_columns = [col for col in df.columns if col not in target_columns]\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for target in target_columns:\n",
    "    y = df[target]\n",
    "\n",
    "    # Step 1: Univariate mutual information filtering\n",
    "    selector = SelectKBest(mutual_info_regression, k=30)  # pick top 30 features\n",
    "    selector.fit(X, y)\n",
    "    X_selected = X.loc[:, selector.get_support()]\n",
    "\n",
    "    # Step 2: Multivariate selection (model-based)\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=20, direction='forward')\n",
    "    sfs.fit(X_selected, y)\n",
    "\n",
    "    selected_features = X_selected.columns[sfs.get_support()].tolist()\n",
    "    results[target] = selected_features\n",
    "\n",
    "for target, features in results.items():\n",
    "    print(f\"\\nSelected features for {target}:\")\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8273969-d0bc-4cb2-84e6-41827cd42870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
